{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70638c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7bcd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"AAPL\"\n",
    "years = [2025, 2024]\n",
    "quarters = [1, 2, 3, 4]\n",
    "fmp_api_key = \"b6adf265209f12e18fd61e2f403585c3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924693b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6496\\2618679024.py:22: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  oaiembeds = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from helper import (\n",
    "    processing_html2txt,\n",
    "    combine_sentences,\n",
    "    calculate_cosine_distances,\n",
    "    find_appropriate_threshold,\n",
    ")\n",
    "from pdf_to_gcp import HtmlToPdfGcpUploader\n",
    "from sec_downloader import Downloader\n",
    "\n",
    "# MongoDB setup\n",
    "mongo_client = MongoClient(os.getenv(\"MONGO_URI\"))\n",
    "db = mongo_client[\"qualitative\"]\n",
    "collection = db[\"earnings\"]\n",
    "\n",
    "# Embedding model (OpenAI)\n",
    "oaiembeds = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "dl = Downloader(\"Traderware\", \"x.tan@traderverse.io\")\n",
    "\n",
    "def process_and_insert_to_mongodb(file):\n",
    "    sentence_texts = re.split(r\"(?<=[.#:])\\s+\", file[0].get(\"content\", \"\"))\n",
    "    sentences = [{\"sentence\": s, \"index\": i} for i, s in enumerate(sentence_texts)]\n",
    "    sentences = combine_sentences(sentences)\n",
    "\n",
    "    # Step 2: Embed each sentence (OpenAI)\n",
    "    embeddings = oaiembeds.embed_documents(\n",
    "        [x[\"combined_sentence\"] for x in sentences]\n",
    "    )\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        sentences[i][\"combined_sentence_embedding\"] = emb\n",
    "\n",
    "    # Step 3: Semantic chunking\n",
    "    distances, sentences = calculate_cosine_distances(sentences)\n",
    "    \n",
    "    threshold, chunks, chunk_sizes = find_appropriate_threshold(sentences, distances, 95, 1000)\n",
    "    breakpoint_distance_threshold = np.percentile(distances, threshold)\n",
    "    indices_above_thresh = [i for i, x in enumerate(distances) if x > breakpoint_distance_threshold]\n",
    "\n",
    "    # Step 4: Group sentences into chunks\n",
    "    chunk_texts = []\n",
    "    start_index = 0\n",
    "    for index in indices_above_thresh:\n",
    "        group = sentences[start_index : index + 1]\n",
    "        chunk_texts.append(\" \".join([d[\"sentence\"] for d in group]))\n",
    "        start_index = index + 1\n",
    "    if start_index < len(sentences):\n",
    "        chunk_texts.append(\" \".join([d[\"sentence\"] for d in sentences[start_index:]]))\n",
    "\n",
    "    # Step 5: Embed chunks with OpenAI\n",
    "    chunk_embeddings = oaiembeds.embed_documents(chunk_texts)\n",
    "\n",
    "    # Step 6: Insert into MongoDB\n",
    "    safe_date = file[0].get(\"date\", \"\")\n",
    "    for chunk, vector in zip(chunk_texts, chunk_embeddings):\n",
    "        doc = {\n",
    "            \"content\": chunk,\n",
    "            \"embedding\": vector,\n",
    "            \"file_name\": \n",
    "                f\"{file[0].get(\"symbol\", \"\")}_{file[0].get(\"period\", \"\")}_{safe_date}\",\n",
    "            \"ticker\": file[0].get(\"symbol\", \"\"),\n",
    "            \"quarter\": file[0].get(\"period\", \"\"),\n",
    "            \"date\": datetime.fromisoformat(safe_date)\n",
    "        }\n",
    "        collection.insert_one(doc)\n",
    "\n",
    "    print(f\"✅ Inserted {len(chunk_texts)} chunks using OpenAI embeddings for: {file[0].get(\"symbol\", \"\")}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110b3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL Q1 2025...\n",
      "✅ Inserted 81 chunks using OpenAI embeddings for: AAPL\n",
      "Fetching AAPL Q2 2025...\n",
      "No data for Q2 2025. Skipping.\n",
      "Fetching AAPL Q3 2025...\n",
      "No data for Q3 2025. Skipping.\n",
      "Fetching AAPL Q4 2025...\n",
      "No data for Q4 2025. Skipping.\n",
      "Fetching AAPL Q1 2024...\n",
      "✅ Inserted 136 chunks using OpenAI embeddings for: AAPL\n",
      "Fetching AAPL Q2 2024...\n",
      "✅ Inserted 114 chunks using OpenAI embeddings for: AAPL\n",
      "Fetching AAPL Q3 2024...\n",
      "✅ Inserted 77 chunks using OpenAI embeddings for: AAPL\n",
      "Fetching AAPL Q4 2024...\n",
      "✅ Inserted 81 chunks using OpenAI embeddings for: AAPL\n"
     ]
    }
   ],
   "source": [
    "# Ingest\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        print(f\"Fetching {symbol} Q{quarter} {year}...\")\n",
    "        url = f\"https://financialmodelingprep.com/stable/earning-call-transcript?symbol={symbol}&year={year}&quarter={quarter}&apikey={fmp_api_key}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if not data:\n",
    "            print(f\"No data for Q{quarter} {year}. Skipping.\")\n",
    "            continue\n",
    "        transcript = data[0].get(\"content\", \"\")\n",
    "        if not transcript:\n",
    "            print(f\"No transcript content for Q{quarter} {year}. Skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            process_and_insert_to_mongodb(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file[0].get(\"date\", \"\")}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb2011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0808889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance, PayloadSchemaType\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from helper import (\n",
    "    processing_html2txt,\n",
    "    combine_sentences,\n",
    "    calculate_cosine_distances,\n",
    "    find_appropriate_threshold,\n",
    ")\n",
    "from sec_downloader import Downloader\n",
    "\n",
    "# Qdrant setup\n",
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "# Embedding model\n",
    "oaiembeds = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "dl = Downloader(\"Traderware\", \"x.tan@traderverse.io\")\n",
    "\n",
    "def process_and_insert_earnings_to_qdrant(file):\n",
    "    # 1️⃣ Sentence splitting\n",
    "    sentence_texts = re.split(r\"(?<=[.#:])\\s+\", file[0].get(\"content\", \"\"))\n",
    "    sentences = [{\"sentence\": s, \"index\": i} for i, s in enumerate(sentence_texts)]\n",
    "    sentences = combine_sentences(sentences)\n",
    "\n",
    "    # 2️⃣ Embed sentences for semantic chunking\n",
    "    sent_embeds = oaiembeds.embed_documents([s[\"combined_sentence\"] for s in sentences])\n",
    "    for i, emb in enumerate(sent_embeds):\n",
    "        sentences[i][\"combined_sentence_embedding\"] = emb\n",
    "\n",
    "    # 3️⃣ Semantic chunking\n",
    "    distances, sentences = calculate_cosine_distances(sentences)\n",
    "    threshold, _, _ = find_appropriate_threshold(sentences, distances, 95, 1000)\n",
    "    break_idx = np.percentile(distances, threshold)\n",
    "    boundaries = [i for i, d in enumerate(distances) if d > break_idx]\n",
    "\n",
    "    chunk_texts = []\n",
    "    start = 0\n",
    "    for b in boundaries:\n",
    "        chunk_texts.append(\" \".join(s[\"sentence\"] for s in sentences[start : b + 1]))\n",
    "        start = b + 1\n",
    "    if start < len(sentences):\n",
    "        chunk_texts.append(\" \".join(s[\"sentence\"] for s in sentences[start:]))\n",
    "\n",
    "    # 4️⃣ Embed chunks\n",
    "    chunk_embeddings = oaiembeds.embed_documents(chunk_texts)\n",
    "\n",
    "    # 5️⃣ Ensure collection + payload index exists\n",
    "    collection_name = \"earnings\"\n",
    "    if not qdrant_client.collection_exists(collection_name):\n",
    "        qdrant_client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=VectorParams(\n",
    "                size=len(chunk_embeddings[0]),\n",
    "                distance=Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "        qdrant_client.create_payload_index(\n",
    "            collection_name=collection_name,\n",
    "            field_name=\"date\",\n",
    "            field_schema=PayloadSchemaType.DATETIME,\n",
    "            wait=True\n",
    "        )\n",
    "\n",
    "    # 6️⃣ Parse & normalize date to \"YYYY-MM-DDThh:mm:ssZ\"\n",
    "    raw_date = file[0].get(\"date\", \"\")\n",
    "    safe_date_iso = None\n",
    "    if raw_date:\n",
    "        try:\n",
    "            dt = datetime.strptime(raw_date, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            dt = datetime.fromisoformat(raw_date)\n",
    "        safe_date_iso = dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    # 7️⃣ Build and upsert points\n",
    "    base_id = int(datetime.now().timestamp() * 1000)\n",
    "    points = []\n",
    "    for idx, (chunk, vector) in enumerate(zip(chunk_texts, chunk_embeddings)):\n",
    "        points.append(\n",
    "            PointStruct(\n",
    "                id=base_id + idx,\n",
    "                vector=vector,\n",
    "                payload={\n",
    "                    \"content\":   chunk,\n",
    "                    \"file_name\": f\"{file[0].get('symbol','')}_{file[0].get('period','')}_{safe_date_iso or ''}\",\n",
    "                    \"ticker\":    file[0].get(\"symbol\", \"\"),\n",
    "                    \"quarter\":   file[0].get(\"period\", \"\"),\n",
    "                    \"date\":      safe_date_iso,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    qdrant_client.upsert(collection_name=collection_name, points=points)\n",
    "    print(f\"✅ Inserted {len(points)} earnings chunks for: {file[0].get('symbol','')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f04f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL Q1 2025...\n",
      "✅ Inserted 81 earnings chunks for: AAPL\n",
      "Fetching AAPL Q2 2025...\n",
      "No data for Q2 2025. Skipping.\n",
      "Fetching AAPL Q3 2025...\n",
      "No data for Q3 2025. Skipping.\n",
      "Fetching AAPL Q4 2025...\n",
      "No data for Q4 2025. Skipping.\n",
      "Fetching AAPL Q1 2024...\n",
      "✅ Inserted 136 earnings chunks for: AAPL\n",
      "Fetching AAPL Q2 2024...\n",
      "✅ Inserted 114 earnings chunks for: AAPL\n",
      "Fetching AAPL Q3 2024...\n",
      "✅ Inserted 77 earnings chunks for: AAPL\n",
      "Fetching AAPL Q4 2024...\n",
      "✅ Inserted 81 earnings chunks for: AAPL\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Ingest\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        print(f\"Fetching {symbol} Q{quarter} {year}...\")\n",
    "        url = f\"https://financialmodelingprep.com/stable/earning-call-transcript?symbol={symbol}&year={year}&quarter={quarter}&apikey={fmp_api_key}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if not data:\n",
    "            print(f\"No data for Q{quarter} {year}. Skipping.\")\n",
    "            continue\n",
    "        transcript = data[0].get(\"content\", \"\")\n",
    "        if not transcript:\n",
    "            print(f\"No transcript content for Q{quarter} {year}. Skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            process_and_insert_earnings_to_qdrant(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {data[0].get(\"date\", \"\")}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1992f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\warnings.py:314: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_6496\\268709408.py:19: ResourceWarning: unclosed <socket.socket fd=4900, family=23, type=1, proto=0, laddr=('::1', 55971, 0, 0), raddr=('::1', 8080, 0, 0)>\n",
      "  client = weaviate.connect_to_local()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "UnexpectedStatusCodeError",
     "evalue": "Collection may not have been created properly.! Unexpected status code: 422, with response body: {'error': [{'message': 'class name Earnings already exists'}]}.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedStatusCodeError\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CLASS_NAME \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m client.collections.list_all(simple=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     24\u001b[39m     class_schema = {\n\u001b[32m     25\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m: CLASS_NAME,\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mChunks of company earnings content with metadata\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m         ],\n\u001b[32m     37\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollections\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_from_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# 2️⃣ Embedding model & downloader\u001b[39;00m\n\u001b[32m     41\u001b[39m oaiembeds = OpenAIEmbeddings(openai_api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\collections\\collections\\sync.py:31\u001b[39m, in \u001b[36m_Collections.create_from_dict\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;129m@executor\u001b[39m.no_wrapping\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_from_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: \u001b[38;5;28mdict\u001b[39m) -> Collection:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     collection = executor.result(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_from_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(collection, Collection)\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m collection\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\collections\\collections\\executor.py:394\u001b[39m, in \u001b[36m_CollectionsExecutor._create_from_dict\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_from_dict\u001b[39m(\n\u001b[32m    391\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    392\u001b[39m     config: \u001b[38;5;28mdict\u001b[39m,\n\u001b[32m    393\u001b[39m ) -> Union[Collection, Awaitable[CollectionAsync]]:\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\collections\\collections\\executor.py:101\u001b[39m, in \u001b[36m_CollectionsExecutor.__create\u001b[39m\u001b[34m(self, config, data_model_properties, data_model_references, skip_argument_validation)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__create\u001b[39m(\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     93\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     Collection[Properties, References], Awaitable[CollectionAsync[Properties, References]]\n\u001b[32m    100\u001b[39m ]:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/schema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCollection may not have been created properly.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ExpectedStatusCodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mok_in\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCreate collection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Awaitable):\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py:806\u001b[39m, in \u001b[36m_ConnectionBase.post\u001b[39m\u001b[34m(self, path, weaviate_object, params, error_msg, status_codes, is_gql_query)\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    799\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    804\u001b[39m     is_gql_query: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    805\u001b[39m ) -> executor.Result[Response]:\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_version_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_gql_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_gql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py:700\u001b[39m, in \u001b[36m_ConnectionBase._send\u001b[39m\u001b[34m(self, method, url, error_msg, status_codes, is_gql_query, weaviate_object, params, check_is_connected)\u001b[39m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexc\u001b[39m(e: \u001b[38;5;167;01mException\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    698\u001b[39m     \u001b[38;5;28mself\u001b[39m.__handle_exceptions(e, error_msg)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexception_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\connect\\executor.py:87\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp_call\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(T, \u001b[43mexception_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py:698\u001b[39m, in \u001b[36m_ConnectionBase._send.<locals>.exc\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexc\u001b[39m(e: \u001b[38;5;167;01mException\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__handle_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py:657\u001b[39m, in \u001b[36m_ConnectionBase.__handle_exceptions\u001b[39m\u001b[34m(self, e, error_msg)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeout):\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateTimeoutError(error_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\connect\\executor.py:83\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m cast(T, exception_callback(e))\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _execute()\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m resp_call = \u001b[43mresponse_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp_call, Awaitable)\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp_call\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py:695\u001b[39m, in \u001b[36m_ConnectionBase._send.<locals>.resp\u001b[39m\u001b[34m(res)\u001b[39m\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresp\u001b[39m(res: Response) -> Response:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__handle_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py:665\u001b[39m, in \u001b[36m_ConnectionBase.__handle_response\u001b[39m\u001b[34m(self, response, error_msg, status_codes)\u001b[39m\n\u001b[32m    663\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InsufficientPermissionsError(response)\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m status_codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m status_codes.ok:\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedStatusCodeError(error_msg, response)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mUnexpectedStatusCodeError\u001b[39m: Collection may not have been created properly.! Unexpected status code: 422, with response body: {'error': [{'message': 'class name Earnings already exists'}]}."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import weaviate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from helper import (\n",
    "    processing_html2txt,\n",
    "    combine_sentences,\n",
    "    calculate_cosine_distances,\n",
    "    find_appropriate_threshold,\n",
    ")\n",
    "from sec_downloader import Downloader\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 🚀 Weaviate client (local Docker)\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "CLASS_NAME = \"earnings\"\n",
    "# 1️⃣ Ensure class schema exists\n",
    "if CLASS_NAME not in client.collections.list_all(simple=True):\n",
    "    class_schema = {\n",
    "        \"class\": CLASS_NAME,\n",
    "        \"description\": \"Chunks of company earnings content with metadata\",\n",
    "        \"vectorizer\": \"none\",\n",
    "        \"vectorIndexType\": \"hnsw\",\n",
    "        \"vectorIndexConfig\": {\"distance\": \"cosine\"},\n",
    "        \"properties\": [\n",
    "            {\"name\": \"content\",    \"dataType\": [\"text\"]},\n",
    "            {\"name\": \"file_name\",  \"dataType\": [\"string\"]},\n",
    "            {\"name\": \"ticker\",     \"dataType\": [\"string\"]},\n",
    "            {\"name\": \"quarter\",    \"dataType\": [\"string\"]},\n",
    "            {\"name\": \"date\",       \"dataType\": [\"date\"]},\n",
    "        ],\n",
    "    }\n",
    "    client.collections.create_from_dict(class_schema)\n",
    "\n",
    "# 2️⃣ Embedding model & downloader\n",
    "oaiembeds = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "dl = Downloader(\"Traderware\", \"x.tan@traderverse.io\")\n",
    "\n",
    "def process_and_insert_earnings_to_weaviate(file):\n",
    "    # A. Sentence split & combine\n",
    "    raw_content = file[0].get(\"content\", \"\")\n",
    "    sentence_texts = re.split(r\"(?<=[.#:])\\s+\", raw_content)\n",
    "    sentences = [{\"sentence\": s, \"index\": i} for i, s in enumerate(sentence_texts)]\n",
    "    sentences = combine_sentences(sentences)\n",
    "\n",
    "    # B. Embed for semantic chunking\n",
    "    sent_texts = [s[\"combined_sentence\"] for s in sentences]\n",
    "    sent_embeds = oaiembeds.embed_documents(sent_texts)\n",
    "    for i, emb in enumerate(sent_embeds):\n",
    "        sentences[i][\"combined_sentence_embedding\"] = emb\n",
    "\n",
    "    # C. Compute boundaries\n",
    "    distances, sentences = calculate_cosine_distances(sentences)\n",
    "    thresh, _, _ = find_appropriate_threshold(sentences, distances, 95, 1000)\n",
    "    break_val = np.percentile(distances, thresh)\n",
    "    boundaries = [i for i, d in enumerate(distances) if d > break_val]\n",
    "\n",
    "    # D. Build chunks\n",
    "    chunk_texts, start = [], 0\n",
    "    for b in boundaries:\n",
    "        chunk_texts.append(\" \".join(s[\"sentence\"] for s in sentences[start:b+1]))\n",
    "        start = b + 1\n",
    "    if start < len(sentences):\n",
    "        chunk_texts.append(\" \".join(s[\"sentence\"] for s in sentences[start:]))\n",
    "\n",
    "    # E. Embed final chunks\n",
    "    chunk_embeddings = oaiembeds.embed_documents(chunk_texts)\n",
    "\n",
    "    # F. Normalize date to ISO\n",
    "    raw_date = file[0].get(\"date\", \"\")\n",
    "    iso_date = \"\"\n",
    "    if raw_date:\n",
    "        try:\n",
    "            dt = datetime.strptime(raw_date, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            dt = datetime.fromisoformat(raw_date)\n",
    "        iso_date = dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    # G. Batch insert via collection-scoped API\n",
    "    collection = client.collections.get(CLASS_NAME)\n",
    "    with collection.batch.fixed_size(batch_size=50, concurrent_requests=4) as batch:\n",
    "        for idx, (chunk, vector) in enumerate(zip(chunk_texts, chunk_embeddings)):\n",
    "            batch.add_object(\n",
    "                properties={\n",
    "                    \"content\":   chunk,\n",
    "                    \"file_name\": f\"{file[0].get('symbol','')}_{file[0].get('period','')}_{iso_date}\",\n",
    "                    \"ticker\":    file[0].get(\"symbol\",\"\"),\n",
    "                    \"quarter\":   file[0].get(\"period\",\"\"),\n",
    "                    \"date\":      iso_date,\n",
    "                },\n",
    "                vector=vector\n",
    "            )\n",
    "\n",
    "    print(f\"✅ Upserted {len(chunk_texts)} earnings chunks for {file[0].get('symbol','')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "addf1000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL Q1 2025...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:503: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response = response.dict()\n",
      "c:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:503: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response = response.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upserted 81 earnings chunks for AAPL\n",
      "Fetching AAPL Q2 2025...\n",
      "No data for Q2 2025. Skipping.\n",
      "Fetching AAPL Q3 2025...\n",
      "No data for Q3 2025. Skipping.\n",
      "Fetching AAPL Q4 2025...\n",
      "No data for Q4 2025. Skipping.\n",
      "Fetching AAPL Q1 2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:503: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response = response.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upserted 136 earnings chunks for AAPL\n",
      "Fetching AAPL Q2 2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:503: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response = response.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upserted 114 earnings chunks for AAPL\n",
      "Fetching AAPL Q3 2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:503: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response = response.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upserted 77 earnings chunks for AAPL\n",
      "Fetching AAPL Q4 2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\RAG_17-04-2025\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:503: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response = response.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upserted 81 earnings chunks for AAPL\n"
     ]
    }
   ],
   "source": [
    "# Ingest\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        print(f\"Fetching {symbol} Q{quarter} {year}...\")\n",
    "        url = f\"https://financialmodelingprep.com/stable/earning-call-transcript?symbol={symbol}&year={year}&quarter={quarter}&apikey={fmp_api_key}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if not data:\n",
    "            print(f\"No data for Q{quarter} {year}. Skipping.\")\n",
    "            continue\n",
    "        transcript = data[0].get(\"content\", \"\")\n",
    "        if not transcript:\n",
    "            print(f\"No transcript content for Q{quarter} {year}. Skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            process_and_insert_earnings_to_weaviate(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {data[0].get(\"date\", \"\")}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430d000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
